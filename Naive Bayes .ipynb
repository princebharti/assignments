{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn\n",
    "!pip install gensim\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective: \n",
    "To classify a review(amazon fine food reviews) into negative or positive class using Naive Bayes algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result: \n",
    "After taking various methods to convert a review to vector , i found that tf-idf version of review applied \n",
    "with Multinomial naive bayes performs well(accuracy=89.75 approx) in comparison with others.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,TimeSeriesSplit,cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB,MultinomialNB\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.metrics import accuracy_score,make_scorer\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,make_scorer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#reading cleaned amazon review csv\n",
    "df=pd.read_csv('cleaned_amazon_reviews.csv')\n",
    "df=df.dropna()\n",
    "\n",
    "df_sample=df #here we can modify our sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample=df_sample.sort_values(by=['Time'],axis=0,ascending=True)  # sorting of dataframe for Time Based splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using Binary BOW and Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting reviews to vector\n",
    "list_of_sentence=[] #list of sentence to be used for countvectorizer\n",
    "for sentence in df_sample['CleanText'].values:\n",
    "    li=sentence\n",
    "    list_of_sentence.append(li)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow_model=CountVectorizer(ngram_range=(1, 2),binary=True) #using  Binary BOW and 1 & 2 grams \n",
    "bow_review_matrix=bow_model.fit_transform(list_of_sentence) #training our model and converting text to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=bow_review_matrix #creating out feature matrix and label vector\n",
    "y=df_sample['class'].apply(lambda string: 1 if string=='positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,shuffle=False) # 70-30 split without shuffling(used for TBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tnr(y_true,y_pred): \n",
    "    tn, fp, fn, tp = confusion_matrix(y_true,y_pred).ravel()\n",
    "    return tn/(tn+fp)\n",
    "\n",
    "def fpr(y_true,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true,y_pred).ravel()\n",
    "    return fp/(tn+fp)\n",
    "\n",
    "def fnr(y_true,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true,y_pred).ravel()\n",
    "    return fn/(fn+tp)\n",
    "\n",
    "def tpr(y_true,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true,y_pred).ravel()\n",
    "    return tp/(fn+tp)\n",
    "\n",
    "tnr=make_scorer(tnr)\n",
    "fpr=make_scorer(fpr)\n",
    "fnr=make_scorer(fnr)\n",
    "tpr=make_scorer(tpr)\n",
    "\n",
    "scoring={'accuracy':'accuracy',\n",
    "    'tnr':tnr,\n",
    "    'fnr':fnr,\n",
    "    'fpr':fpr,\n",
    "    'tpr':tpr,\n",
    "    'precision':'precision',\n",
    "    'recall':'recall',\n",
    "    'f1':'f1',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.metrics import accuracy_score#training stage\n",
    "tscv=TimeSeriesSplit(n_splits=10) # timeseries split for using timeseries based cross-validation\n",
    "weight_vector_y_train=compute_sample_weight(class_weight='balanced',y=y_train) #oversampling to balance the dataset\n",
    "#creating list's to store scores for each value of alpha for each score\n",
    "accuracy=[]\n",
    "tpr=[]\n",
    "tnr=[]\n",
    "fpr=[]\n",
    "fnr=[]\n",
    "f1=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "alpha_list=[0.7,0.8,0.9,1,1.2,1.4] # alpha used for cross validation\n",
    "for alpha in alpha_list:\n",
    "    nb_clf_model=BernoulliNB(alpha=alpha)\n",
    "    cv_dict=cross_validate(nb_clf_model,X_train,y_train,scoring=scoring,cv=tscv.split(X_train),fit_params={'sample_weight':weight_vector_y_train})\n",
    "    accuracy.append(np.mean(cv_dict['test_accuracy']))\n",
    "    tnr.append(np.mean(cv_dict['test_tnr']))\n",
    "    fnr.append(np.mean(cv_dict['test_fnr']))\n",
    "    fpr.append(np.mean(cv_dict['test_fpr']))\n",
    "    tpr.append(np.mean(cv_dict['test_tpr']))\n",
    "    f1.append(np.mean(cv_dict['test_f1']))\n",
    "    precision.append(np.mean(cv_dict['test_precision']))\n",
    "    recall.append(np.mean(cv_dict['test_recall'].mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TNR</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FNR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Precesion</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>0.899909</td>\n",
       "      <td>0.442153</td>\n",
       "      <td>0.977935</td>\n",
       "      <td>0.022065</td>\n",
       "      <td>0.557847</td>\n",
       "      <td>0.911300</td>\n",
       "      <td>0.977935</td>\n",
       "      <td>0.943053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.898064</td>\n",
       "      <td>0.428957</td>\n",
       "      <td>0.978101</td>\n",
       "      <td>0.021899</td>\n",
       "      <td>0.571043</td>\n",
       "      <td>0.909413</td>\n",
       "      <td>0.978101</td>\n",
       "      <td>0.942083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>0.896381</td>\n",
       "      <td>0.416034</td>\n",
       "      <td>0.978462</td>\n",
       "      <td>0.021538</td>\n",
       "      <td>0.583966</td>\n",
       "      <td>0.907536</td>\n",
       "      <td>0.978462</td>\n",
       "      <td>0.941210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.894851</td>\n",
       "      <td>0.404465</td>\n",
       "      <td>0.978788</td>\n",
       "      <td>0.021212</td>\n",
       "      <td>0.595535</td>\n",
       "      <td>0.905831</td>\n",
       "      <td>0.978788</td>\n",
       "      <td>0.940417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2</th>\n",
       "      <td>0.891863</td>\n",
       "      <td>0.381213</td>\n",
       "      <td>0.979610</td>\n",
       "      <td>0.020390</td>\n",
       "      <td>0.618787</td>\n",
       "      <td>0.902355</td>\n",
       "      <td>0.979610</td>\n",
       "      <td>0.938879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.4</th>\n",
       "      <td>0.889392</td>\n",
       "      <td>0.361819</td>\n",
       "      <td>0.980396</td>\n",
       "      <td>0.019604</td>\n",
       "      <td>0.638181</td>\n",
       "      <td>0.899409</td>\n",
       "      <td>0.980396</td>\n",
       "      <td>0.937614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy       TNR       TPR       FNR       FPR  Precesion    Recall  \\\n",
       "alpha                                                                          \n",
       "0.7    0.899909  0.442153  0.977935  0.022065  0.557847   0.911300  0.977935   \n",
       "0.8    0.898064  0.428957  0.978101  0.021899  0.571043   0.909413  0.978101   \n",
       "0.9    0.896381  0.416034  0.978462  0.021538  0.583966   0.907536  0.978462   \n",
       "1.0    0.894851  0.404465  0.978788  0.021212  0.595535   0.905831  0.978788   \n",
       "1.2    0.891863  0.381213  0.979610  0.020390  0.618787   0.902355  0.979610   \n",
       "1.4    0.889392  0.361819  0.980396  0.019604  0.638181   0.899409  0.980396   \n",
       "\n",
       "             F1  \n",
       "alpha            \n",
       "0.7    0.943053  \n",
       "0.8    0.942083  \n",
       "0.9    0.941210  \n",
       "1.0    0.940417  \n",
       "1.2    0.938879  \n",
       "1.4    0.937614  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df=pd.DataFrame(OrderedDict({'Accuracy':accuracy,'TNR':tnr,'TPR':tpr,'FNR':fnr,'FPR':fpr,'Precesion':precision,'Recall':recall,'F1':f1}),index=alpha_list)   \n",
    "score_df.index.name='alpha'\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_score(y_true,y_predicted,sample_weight=None):\n",
    "    '''\n",
    "    calculation of all 4 ratios of confusion matrix\n",
    "    and returing dict consisting all rations\n",
    "    '''\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true,y_predicted).ravel()\n",
    "    tnr=tn/(tn+fp)\n",
    "    fpr=fp/(tn+fp)\n",
    "    fnr=fn/(fn+tp)\n",
    "    tpr=tp/(fn+tp)\n",
    "    return {'tnr':tnr,'tpr':tpr,'fpr':fpr,'fnr':fnr}\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please enter optimal alpha  0.7\n",
      "Accuracy=  85.2849958808  %\n",
      "TNR=  74.7099377838  %\n",
      "TPR=  95.8600539778  %\n",
      "FNR=  4.13994602223  %\n",
      "FPR=  25.2900622162  %\n",
      "Precesion=  79.1250202552  %\n",
      "Recall=  95.8600539778  %\n",
      "F1=  86.6922935674  %\n"
     ]
    }
   ],
   "source": [
    "#test stage/evaluation stage\n",
    "#retrianing our model with optimal hyperparameter:\n",
    "optimal_alpha=float(input('please enter optimal alpha  '))\n",
    "nb_clf_model=BernoulliNB(alpha=optimal_alpha)\n",
    "weight_vector_y_train=compute_sample_weight(class_weight='balanced',y=y_train) #oversampling to balance the dataset\n",
    "nb_clf_model.fit(X_train,y_train,sample_weight=weight_vector_y_train)\n",
    "\n",
    "#evaluating our model\n",
    "weight_vector_y_test=compute_sample_weight(class_weight='balanced',y=y_test) #oversampling to balance the dataset\n",
    "y_predicted=nb_clf_model.predict(X_test)\n",
    "accuracy=accuracy_score(y_test,y_predicted,normalize=True,sample_weight=weight_vector_y_test)\n",
    "precesion=precision_score(y_test,y_predicted,sample_weight=weight_vector_y_test)\n",
    "recall=recall_score(y_test,y_predicted,sample_weight=weight_vector_y_test)\n",
    "f1=f1_score(y_test,y_predicted,sample_weight=weight_vector_y_test)\n",
    "confusion_result=confusion_score(y_test,y_predicted,sample_weight=weight_vector_y_test)\n",
    "print('Accuracy= ',accuracy*100,' %')\n",
    "print('TNR= ',confusion_result['tnr']*100,' %')\n",
    "print('TPR= ',confusion_result['tpr']*100,' %')\n",
    "print('FNR= ',confusion_result['fnr']*100,' %')\n",
    "print('FPR= ',confusion_result['fpr']*100,' %')\n",
    "print('Precesion= ',precesion*100,' %')\n",
    "print('Recall= ',recall*100,' %')\n",
    "print('F1= ',f1*100,' %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_prob=pd.DataFrame({'negative':nb_clf_model.feature_log_prob_[0,:],'positive':nb_clf_model.feature_log_prob_[1,:],'feature':bow_model.get_feature_names()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1850292        not\n",
       "1563628       like\n",
       "2736080       tast\n",
       "1620760       love\n",
       "1185785       good\n",
       "1217211      great\n",
       "2787022        the\n",
       "2826533       this\n",
       "1042761     flavor\n",
       "1910210        one\n",
       "2974007        use\n",
       "2907733        tri\n",
       "2147763    product\n",
       "1651550       make\n",
       "1149117        get\n",
       "383137         buy\n",
       "2849770       time\n",
       "251097        best\n",
       "3135268      would\n",
       "1019034       find\n",
       "2231983     realli\n",
       "2128916      price\n",
       "88702       amazon\n",
       "1786405       much\n",
       "854640         eat\n",
       "74927         also\n",
       "807909        dont\n",
       "1588739      littl\n",
       "1933196      order\n",
       "2637615      store\n",
       "            ...   \n",
       "274010         bit\n",
       "1972621     packag\n",
       "2674125      sugar\n",
       "562145        come\n",
       "2817112      thing\n",
       "1615976        lot\n",
       "1499477       know\n",
       "761033      differ\n",
       "1664342       mani\n",
       "417932        cant\n",
       "2937892        two\n",
       "2380079        say\n",
       "632769       could\n",
       "675431         cup\n",
       "925109       everi\n",
       "2625958      still\n",
       "1598803      local\n",
       "499957      chocol\n",
       "83555        alway\n",
       "3110998    without\n",
       "3045051      water\n",
       "2901342      treat\n",
       "3116145     wonder\n",
       "799305         dog\n",
       "1824647      never\n",
       "2725076       take\n",
       "922660        ever\n",
       "849287        easi\n",
       "1105181      fresh\n",
       "2522081      snack\n",
       "Name: feature, Length: 100, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top 100 feature for positive class\n",
    "feature_prob.sort_values(by=['positive'],axis=0,ascending=False)['feature'][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1850292           not\n",
       "2736080          tast\n",
       "1563628          like\n",
       "2787022           the\n",
       "2147763       product\n",
       "1910210           one\n",
       "3135268         would\n",
       "2907733           tri\n",
       "2826533          this\n",
       "1185785          good\n",
       "1042761        flavor\n",
       "383137            buy\n",
       "1149117           get\n",
       "2974007           use\n",
       "807909           dont\n",
       "1933196         order\n",
       "917016           even\n",
       "1651550          make\n",
       "1786405          much\n",
       "2849770          time\n",
       "2231983        realli\n",
       "1620760          love\n",
       "1608367          look\n",
       "88702          amazon\n",
       "315343         bought\n",
       "322642            box\n",
       "854640            eat\n",
       "776139     disappoint\n",
       "1069061          food\n",
       "2179667       purchas\n",
       "              ...    \n",
       "826659          drink\n",
       "3045051         water\n",
       "1089200         found\n",
       "1348038         howev\n",
       "2513803         smell\n",
       "2247587     recommend\n",
       "2752048           tea\n",
       "376064            but\n",
       "1397810       ingredi\n",
       "417932           cant\n",
       "173671           away\n",
       "3150313          year\n",
       "499957         chocol\n",
       "2482747          sinc\n",
       "2800629         there\n",
       "2674125         sugar\n",
       "1432686            it\n",
       "2410920          seem\n",
       "2783176          that\n",
       "701518            day\n",
       "797346         doesnt\n",
       "2695058          sure\n",
       "1748609           mix\n",
       "2657844         stuff\n",
       "2405574           see\n",
       "1903232           old\n",
       "2454181          ship\n",
       "16025          actual\n",
       "799305            dog\n",
       "603397        contain\n",
       "Name: feature, Length: 100, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top 100 feature for negative class\n",
    "feature_prob.sort_values(by=['negative'],axis=0,ascending=False)['feature'][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How confusion matrix can help us to understand about dumb models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TNR=  23.7654839975  %\n",
      "TPR=  94.4437566544  %\n",
      "FNR=  5.55624334563  %\n",
      "FPR=  76.2345160025  %\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix  considering unbalanced data\n",
    "nb_clf_model=BernoulliNB(alpha=optimal_alpha)\n",
    "nb_clf_model.fit(X_train,y_train)\n",
    "y_predicted=nb_clf_model.predict(X_test)\n",
    "confusion_result=confusion_score(y_test,y_predicted)\n",
    "print('TNR= ',confusion_result['tnr']*100,' %')\n",
    "print('TPR= ',confusion_result['tpr']*100,' %')\n",
    "print('FNR= ',confusion_result['fnr']*100,' %')\n",
    "print('FPR= ',confusion_result['fpr']*100,' %')\n",
    "# so we can see how bad TNR and FPR if we are modeling Naive Bayes algo with unbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### so here  we can see how bad TNR and FPR if we are modeling Naive Bayes algo with unbalanced data, so we can say that model is positive class has undue advantage over negative class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using count based BOW and multinomial naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting reviews to vector\n",
    "list_of_sentence=[] #list of sentence to be used for countvectorizer\n",
    "for sentence in df_sample['CleanText'].values:\n",
    "    li=sentence\n",
    "    list_of_sentence.append(li)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow_model=CountVectorizer(ngram_range=(1, 2),binary=False) #using count-BOW and 1 & 2 grams \n",
    "bow_review_matrix=bow_model.fit_transform(list_of_sentence) #training our model and converting text to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=bow_review_matrix #creating out feature matrix and label vector\n",
    "y=df_sample['class'].apply(lambda string: 1 if string=='positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,shuffle=False) # 70-30 split without shuffling(used for TBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tnr(y_true,y_pred): \n",
    "    tn, fp, fn, tp = confusion_matrix(y_true,y_pred).ravel()\n",
    "    return tn/(tn+fp)\n",
    "\n",
    "def fpr(y_true,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true,y_pred).ravel()\n",
    "    return fp/(tn+fp)\n",
    "\n",
    "def fnr(y_true,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true,y_pred).ravel()\n",
    "    return fn/(fn+tp)\n",
    "\n",
    "def tpr(y_true,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true,y_pred).ravel()\n",
    "    return tp/(fn+tp)\n",
    "\n",
    "tnr=make_scorer(tnr)\n",
    "fpr=make_scorer(fpr)\n",
    "fnr=make_scorer(fnr)\n",
    "tpr=make_scorer(tpr)\n",
    "\n",
    "scoring={'accuracy':'accuracy',\n",
    "    'tnr':tnr,\n",
    "    'fnr':fnr,\n",
    "    'fpr':fpr,\n",
    "    'tpr':tpr,\n",
    "    'precision':'precision',\n",
    "    'recall':'recall',\n",
    "    'f1':'f1',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.metrics import accuracy_score#training stage\n",
    "tscv=TimeSeriesSplit(n_splits=10) # timeseries split for using timeseries based cross-validation\n",
    "weight_vector_y_train=compute_sample_weight(class_weight='balanced',y=y_train) #oversampling to balance the dataset\n",
    "#creating list's to store scores for each value of alpha for each score\n",
    "accuracy=[]\n",
    "tpr=[]\n",
    "tnr=[]\n",
    "fpr=[]\n",
    "fnr=[]\n",
    "f1=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "alpha_list=[0.7,0.8,0.9,1,1.2,1.4] # alpha used for cross validation\n",
    "for alpha in alpha_list:\n",
    "    nb_clf_model=MultinomialNB(alpha=alpha)\n",
    "    cv_dict=cross_validate(nb_clf_model,X_train,y_train,scoring=scoring,cv=tscv.split(X_train),fit_params={'sample_weight':weight_vector_y_train})\n",
    "    accuracy.append(np.mean(cv_dict['test_accuracy']))\n",
    "    tnr.append(np.mean(cv_dict['test_tnr']))\n",
    "    fnr.append(np.mean(cv_dict['test_fnr']))\n",
    "    fpr.append(np.mean(cv_dict['test_fpr']))\n",
    "    tpr.append(np.mean(cv_dict['test_tpr']))\n",
    "    f1.append(np.mean(cv_dict['test_f1']))\n",
    "    precision.append(np.mean(cv_dict['test_precision']))\n",
    "    recall.append(np.mean(cv_dict['test_recall'].mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TNR</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FNR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Precesion</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>0.916976</td>\n",
       "      <td>0.677417</td>\n",
       "      <td>0.956944</td>\n",
       "      <td>0.043056</td>\n",
       "      <td>0.322583</td>\n",
       "      <td>0.945633</td>\n",
       "      <td>0.956944</td>\n",
       "      <td>0.950998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.916909</td>\n",
       "      <td>0.681498</td>\n",
       "      <td>0.955960</td>\n",
       "      <td>0.044040</td>\n",
       "      <td>0.318502</td>\n",
       "      <td>0.946472</td>\n",
       "      <td>0.955960</td>\n",
       "      <td>0.950902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>0.916789</td>\n",
       "      <td>0.684731</td>\n",
       "      <td>0.955072</td>\n",
       "      <td>0.044928</td>\n",
       "      <td>0.315269</td>\n",
       "      <td>0.947174</td>\n",
       "      <td>0.955072</td>\n",
       "      <td>0.950786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.916541</td>\n",
       "      <td>0.687240</td>\n",
       "      <td>0.954166</td>\n",
       "      <td>0.045834</td>\n",
       "      <td>0.312760</td>\n",
       "      <td>0.947753</td>\n",
       "      <td>0.954166</td>\n",
       "      <td>0.950594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2</th>\n",
       "      <td>0.915762</td>\n",
       "      <td>0.690262</td>\n",
       "      <td>0.952456</td>\n",
       "      <td>0.047544</td>\n",
       "      <td>0.309738</td>\n",
       "      <td>0.948485</td>\n",
       "      <td>0.952456</td>\n",
       "      <td>0.950051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.4</th>\n",
       "      <td>0.914930</td>\n",
       "      <td>0.693008</td>\n",
       "      <td>0.950779</td>\n",
       "      <td>0.049221</td>\n",
       "      <td>0.306992</td>\n",
       "      <td>0.949121</td>\n",
       "      <td>0.950779</td>\n",
       "      <td>0.949474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy       TNR       TPR       FNR       FPR  Precesion    Recall  \\\n",
       "alpha                                                                          \n",
       "0.7    0.916976  0.677417  0.956944  0.043056  0.322583   0.945633  0.956944   \n",
       "0.8    0.916909  0.681498  0.955960  0.044040  0.318502   0.946472  0.955960   \n",
       "0.9    0.916789  0.684731  0.955072  0.044928  0.315269   0.947174  0.955072   \n",
       "1.0    0.916541  0.687240  0.954166  0.045834  0.312760   0.947753  0.954166   \n",
       "1.2    0.915762  0.690262  0.952456  0.047544  0.309738   0.948485  0.952456   \n",
       "1.4    0.914930  0.693008  0.950779  0.049221  0.306992   0.949121  0.950779   \n",
       "\n",
       "             F1  \n",
       "alpha            \n",
       "0.7    0.950998  \n",
       "0.8    0.950902  \n",
       "0.9    0.950786  \n",
       "1.0    0.950594  \n",
       "1.2    0.950051  \n",
       "1.4    0.949474  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df=pd.DataFrame(OrderedDict({'Accuracy':accuracy,'TNR':tnr,'TPR':tpr,'FNR':fnr,'FPR':fpr,'Precesion':precision,'Recall':recall,'F1':f1}),index=alpha_list)   \n",
    "score_df.index.name='alpha'\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_score(y_true,y_predicted,sample_weight=None):\n",
    "    '''\n",
    "    calculation of all 4 ratios of confusion matrix\n",
    "    and returing dict consisting all rations\n",
    "    '''\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true,y_predicted).ravel()\n",
    "    tnr=tn/(tn+fp)\n",
    "    fpr=fp/(tn+fp)\n",
    "    fnr=fn/(fn+tp)\n",
    "    tpr=tp/(fn+tp)\n",
    "    return {'tnr':tnr,'tpr':tpr,'fpr':fpr,'fnr':fnr}\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please enter optimal alpha  0.7\n",
      "Accuracy=  87.3790182404  %\n",
      "TNR=  80.8082506586  %\n",
      "TPR=  93.9497858222  %\n",
      "FNR=  6.05021417783  %\n",
      "FPR=  19.1917493414  %\n",
      "Precesion=  83.0373970853  %\n",
      "Recall=  93.9497858222  %\n",
      "F1=  88.1571822686  %\n"
     ]
    }
   ],
   "source": [
    "#test stage/evaluation stage\n",
    "#retrianing our model with optimal hyperparameter:\n",
    "optimal_alpha=float(input('please enter optimal alpha  '))\n",
    "nb_clf_model=MultinomialNB(alpha=optimal_alpha)\n",
    "weight_vector_y_train=compute_sample_weight(class_weight='balanced',y=y_train) #oversampling to balance the dataset\n",
    "nb_clf_model.fit(X_train,y_train,sample_weight=weight_vector_y_train)\n",
    "\n",
    "#evaluating our model\n",
    "weight_vector_y_test=compute_sample_weight(class_weight='balanced',y=y_test) #oversampling to balance the dataset\n",
    "y_predicted=nb_clf_model.predict(X_test)\n",
    "accuracy=accuracy_score(y_test,y_predicted,normalize=True,sample_weight=weight_vector_y_test)\n",
    "precesion=precision_score(y_test,y_predicted,sample_weight=weight_vector_y_test)\n",
    "recall=recall_score(y_test,y_predicted,sample_weight=weight_vector_y_test)\n",
    "f1=f1_score(y_test,y_predicted,sample_weight=weight_vector_y_test)\n",
    "confusion_result=confusion_score(y_test,y_predicted,sample_weight=weight_vector_y_test)\n",
    "print('Accuracy= ',accuracy*100,' %')\n",
    "print('TNR= ',confusion_result['tnr']*100,' %')\n",
    "print('TPR= ',confusion_result['tpr']*100,' %')\n",
    "print('FNR= ',confusion_result['fnr']*100,' %')\n",
    "print('FPR= ',confusion_result['fpr']*100,' %')\n",
    "print('Precesion= ',precesion*100,' %')\n",
    "print('Recall= ',recall*100,' %')\n",
    "print('F1= ',f1*100,' %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_prob=pd.DataFrame({'negative':nb_clf_model.feature_log_prob_[0,:],'positive':nb_clf_model.feature_log_prob_[1,:],'feature':bow_model.get_feature_names()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1850292        not\n",
       "1563628       like\n",
       "2736080       tast\n",
       "1185785       good\n",
       "1620760       love\n",
       "2787022        the\n",
       "1042761     flavor\n",
       "2974007        use\n",
       "1217211      great\n",
       "1910210        one\n",
       "2147763    product\n",
       "2907733        tri\n",
       "2752048        tea\n",
       "2826533       this\n",
       "543608       coffe\n",
       "1651550       make\n",
       "1149117        get\n",
       "1069061       food\n",
       "3135268      would\n",
       "383137         buy\n",
       "2849770       time\n",
       "854640         eat\n",
       "2231983     realli\n",
       "1019034       find\n",
       "251097        best\n",
       "2128916      price\n",
       "88702       amazon\n",
       "1786405       much\n",
       "1933196      order\n",
       "1588739      littl\n",
       "            ...   \n",
       "2821173      think\n",
       "992023     favorit\n",
       "1815777       need\n",
       "274010         bit\n",
       "315343      bought\n",
       "2482747       sinc\n",
       "2027065    perfect\n",
       "1475198       keep\n",
       "441136         cat\n",
       "2817112      thing\n",
       "2937892        two\n",
       "761033      differ\n",
       "562145        come\n",
       "1499477       know\n",
       "1615976        lot\n",
       "2522081      snack\n",
       "1664342       mani\n",
       "2380079        say\n",
       "632769       could\n",
       "1339075        hot\n",
       "1099117       free\n",
       "2625958      still\n",
       "1727410       milk\n",
       "925109       everi\n",
       "417932        cant\n",
       "2725076       take\n",
       "83555        alway\n",
       "1598803      local\n",
       "1105181      fresh\n",
       "3110998    without\n",
       "Name: feature, Length: 100, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top 100 feature for positive class\n",
    "feature_prob.sort_values(by=['positive'],axis=0,ascending=False)['feature'][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1850292          not\n",
       "2736080         tast\n",
       "1563628         like\n",
       "2147763      product\n",
       "2787022          the\n",
       "1910210          one\n",
       "1042761       flavor\n",
       "3135268        would\n",
       "2907733          tri\n",
       "543608         coffe\n",
       "2974007          use\n",
       "1185785         good\n",
       "2826533         this\n",
       "1149117          get\n",
       "383137           buy\n",
       "1933196        order\n",
       "2752048          tea\n",
       "807909          dont\n",
       "1069061         food\n",
       "322642           box\n",
       "917016          even\n",
       "1651550         make\n",
       "88702         amazon\n",
       "1786405         much\n",
       "2849770         time\n",
       "190642           bag\n",
       "2231983       realli\n",
       "854640           eat\n",
       "1608367         look\n",
       "1620760         love\n",
       "             ...    \n",
       "2544849       someth\n",
       "1438069         item\n",
       "2817112        thing\n",
       "1748609          mix\n",
       "1924247         open\n",
       "1763894        money\n",
       "675431           cup\n",
       "761033        differ\n",
       "2625958        still\n",
       "181608          back\n",
       "2454181         ship\n",
       "701518           day\n",
       "3150313         year\n",
       "2704921        sweet\n",
       "1089200        found\n",
       "2657844        stuff\n",
       "603397       contain\n",
       "376064           but\n",
       "1969625         pack\n",
       "570250       compani\n",
       "441136           cat\n",
       "417932          cant\n",
       "2247587    recommend\n",
       "2482747         sinc\n",
       "1348038        howev\n",
       "1432686           it\n",
       "2410920         seem\n",
       "2783176         that\n",
       "797346        doesnt\n",
       "173671          away\n",
       "Name: feature, Length: 100, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top 100 feature for negative class\n",
    "feature_prob.sort_values(by=['negative'],axis=0,ascending=False)['feature'][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using tfidf-BOW and multinomial naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting reviews to vector\n",
    "list_of_sentence=[] #list of sentence to be used for countvectorizer\n",
    "for sentence in df_sample['CleanText'].values:\n",
    "    li=sentence\n",
    "    list_of_sentence.append(li)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_model=TfidfVectorizer(ngram_range=(1, 2)) #using count-BOW and 1 & 2 grams \n",
    "tfidf_bow_review_matrix=tfidf_model.fit_transform(list_of_sentence) #training our model and converting text to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=tfidf_bow_review_matrix#creating out feature matrix and label vector\n",
    "y=df_sample['class'].apply(lambda string: 1 if string=='positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,shuffle=False) # 70-30 split without shuffling(used for TBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tnr(y_true,y_pred): \n",
    "    tn, fp, fn, tp = confusion_matrix(y_true,y_pred).ravel()\n",
    "    return tn/(tn+fp)\n",
    "\n",
    "def fpr(y_true,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true,y_pred).ravel()\n",
    "    return fp/(tn+fp)\n",
    "\n",
    "def fnr(y_true,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true,y_pred).ravel()\n",
    "    return fn/(fn+tp)\n",
    "\n",
    "def tpr(y_true,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true,y_pred).ravel()\n",
    "    return tp/(fn+tp)\n",
    "\n",
    "tnr=make_scorer(tnr)\n",
    "fpr=make_scorer(fpr)\n",
    "fnr=make_scorer(fnr)\n",
    "tpr=make_scorer(tpr)\n",
    "\n",
    "scoring={'accuracy':'accuracy',\n",
    "    'tnr':tnr,\n",
    "    'fnr':fnr,\n",
    "    'fpr':fpr,\n",
    "    'tpr':tpr,\n",
    "    'precision':'precision',\n",
    "    'recall':'recall',\n",
    "    'f1':'f1',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.metrics import accuracy_score#training stage\n",
    "tscv=TimeSeriesSplit(n_splits=10) # timeseries split for using timeseries based cross-validation\n",
    "weight_vector_y_train=compute_sample_weight(class_weight='balanced',y=y_train) #oversampling to balance the dataset\n",
    "#creating list's to store scores for each value of alpha for each score\n",
    "accuracy=[]\n",
    "tpr=[]\n",
    "tnr=[]\n",
    "fpr=[]\n",
    "fnr=[]\n",
    "f1=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "alpha_list=[0.7,0.8,0.9,1,1.2,1.4] # alpha used for cross validation\n",
    "for alpha in alpha_list:\n",
    "    nb_clf_model=MultinomialNB(alpha=alpha)\n",
    "    cv_dict=cross_validate(nb_clf_model,X_train,y_train,scoring=scoring,cv=tscv.split(X_train),fit_params={'sample_weight':weight_vector_y_train})\n",
    "    accuracy.append(np.mean(cv_dict['test_accuracy']))\n",
    "    tnr.append(np.mean(cv_dict['test_tnr']))\n",
    "    fnr.append(np.mean(cv_dict['test_fnr']))\n",
    "    fpr.append(np.mean(cv_dict['test_fpr']))\n",
    "    tpr.append(np.mean(cv_dict['test_tpr']))\n",
    "    f1.append(np.mean(cv_dict['test_f1']))\n",
    "    precision.append(np.mean(cv_dict['test_precision']))\n",
    "    recall.append(np.mean(cv_dict['test_recall'].mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TNR</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FNR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Precesion</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>0.914084</td>\n",
       "      <td>0.632740</td>\n",
       "      <td>0.959644</td>\n",
       "      <td>0.040356</td>\n",
       "      <td>0.367260</td>\n",
       "      <td>0.941118</td>\n",
       "      <td>0.959644</td>\n",
       "      <td>0.949515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.913572</td>\n",
       "      <td>0.630166</td>\n",
       "      <td>0.959383</td>\n",
       "      <td>0.040617</td>\n",
       "      <td>0.369834</td>\n",
       "      <td>0.940868</td>\n",
       "      <td>0.959383</td>\n",
       "      <td>0.949214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>0.912965</td>\n",
       "      <td>0.627448</td>\n",
       "      <td>0.959058</td>\n",
       "      <td>0.040942</td>\n",
       "      <td>0.372552</td>\n",
       "      <td>0.940550</td>\n",
       "      <td>0.959058</td>\n",
       "      <td>0.948857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.912573</td>\n",
       "      <td>0.624542</td>\n",
       "      <td>0.959033</td>\n",
       "      <td>0.040967</td>\n",
       "      <td>0.375458</td>\n",
       "      <td>0.940213</td>\n",
       "      <td>0.959033</td>\n",
       "      <td>0.948641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2</th>\n",
       "      <td>0.911994</td>\n",
       "      <td>0.619544</td>\n",
       "      <td>0.959109</td>\n",
       "      <td>0.040891</td>\n",
       "      <td>0.380456</td>\n",
       "      <td>0.939630</td>\n",
       "      <td>0.959109</td>\n",
       "      <td>0.948326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.4</th>\n",
       "      <td>0.911129</td>\n",
       "      <td>0.614205</td>\n",
       "      <td>0.958941</td>\n",
       "      <td>0.041059</td>\n",
       "      <td>0.385795</td>\n",
       "      <td>0.938920</td>\n",
       "      <td>0.958941</td>\n",
       "      <td>0.947833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy       TNR       TPR       FNR       FPR  Precesion    Recall  \\\n",
       "alpha                                                                          \n",
       "0.7    0.914084  0.632740  0.959644  0.040356  0.367260   0.941118  0.959644   \n",
       "0.8    0.913572  0.630166  0.959383  0.040617  0.369834   0.940868  0.959383   \n",
       "0.9    0.912965  0.627448  0.959058  0.040942  0.372552   0.940550  0.959058   \n",
       "1.0    0.912573  0.624542  0.959033  0.040967  0.375458   0.940213  0.959033   \n",
       "1.2    0.911994  0.619544  0.959109  0.040891  0.380456   0.939630  0.959109   \n",
       "1.4    0.911129  0.614205  0.958941  0.041059  0.385795   0.938920  0.958941   \n",
       "\n",
       "             F1  \n",
       "alpha            \n",
       "0.7    0.949515  \n",
       "0.8    0.949214  \n",
       "0.9    0.948857  \n",
       "1.0    0.948641  \n",
       "1.2    0.948326  \n",
       "1.4    0.947833  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df=pd.DataFrame(OrderedDict({'Accuracy':accuracy,'TNR':tnr,'TPR':tpr,'FNR':fnr,'FPR':fpr,'Precesion':precision,'Recall':recall,'F1':f1}),index=alpha_list)   \n",
    "score_df.index.name='alpha'\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_score(y_true,y_predicted,sample_weight=None):\n",
    "    '''\n",
    "    calculation of all 4 ratios of confusion matrix\n",
    "    and returing dict consisting all rations\n",
    "    '''\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true,y_predicted).ravel()\n",
    "    tnr=tn/(tn+fp)\n",
    "    fpr=fp/(tn+fp)\n",
    "    fnr=fn/(fn+tp)\n",
    "    tpr=tp/(fn+tp)\n",
    "    return {'tnr':tnr,'tpr':tpr,'fpr':fpr,'fnr':fnr}\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please enter optimal alpha  0.7\n",
      "Accuracy=  89.7325604264  %\n",
      "TNR=  89.2046409955  %\n",
      "TPR=  90.2604798574  %\n",
      "FNR=  9.73952014262  %\n",
      "FPR=  10.7953590045  %\n",
      "Precesion=  89.317431703  %\n",
      "Recall=  90.2604798574  %\n",
      "F1=  89.7864795853  %\n"
     ]
    }
   ],
   "source": [
    "#test stage/evaluation stage\n",
    "#retrianing our model with optimal hyperparameter:\n",
    "optimal_alpha=float(input('please enter optimal alpha  '))\n",
    "nb_clf_model=MultinomialNB(alpha=optimal_alpha)\n",
    "weight_vector_y_train=compute_sample_weight(class_weight='balanced',y=y_train) #oversampling to balance the dataset\n",
    "nb_clf_model.fit(X_train,y_train,sample_weight=weight_vector_y_train)\n",
    "\n",
    "#evaluating our model\n",
    "weight_vector_y_test=compute_sample_weight(class_weight='balanced',y=y_test) #oversampling to balance the dataset\n",
    "y_predicted=nb_clf_model.predict(X_test)\n",
    "accuracy=accuracy_score(y_test,y_predicted,normalize=True,sample_weight=weight_vector_y_test)\n",
    "precesion=precision_score(y_test,y_predicted,sample_weight=weight_vector_y_test)\n",
    "recall=recall_score(y_test,y_predicted,sample_weight=weight_vector_y_test)\n",
    "f1=f1_score(y_test,y_predicted,sample_weight=weight_vector_y_test)\n",
    "confusion_result=confusion_score(y_test,y_predicted,sample_weight=weight_vector_y_test)\n",
    "print('Accuracy= ',accuracy*100,' %')\n",
    "print('TNR= ',confusion_result['tnr']*100,' %')\n",
    "print('TPR= ',confusion_result['tpr']*100,' %')\n",
    "print('FNR= ',confusion_result['fnr']*100,' %')\n",
    "print('FPR= ',confusion_result['fpr']*100,' %')\n",
    "print('Precesion= ',precesion*100,' %')\n",
    "print('Recall= ',recall*100,' %')\n",
    "print('F1= ',f1*100,' %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_prob=pd.DataFrame({'negative':nb_clf_model.feature_log_prob_[0,:],'positive':nb_clf_model.feature_log_prob_[1,:],'feature':tfidf_model.get_feature_names()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1620760       love\n",
       "1217211      great\n",
       "2736080       tast\n",
       "2752048        tea\n",
       "1563628       like\n",
       "1185785       good\n",
       "1850292        not\n",
       "1042761     flavor\n",
       "543608       coffe\n",
       "2974007        use\n",
       "2826533       this\n",
       "2147763    product\n",
       "2787022        the\n",
       "1910210        one\n",
       "2907733        tri\n",
       "1651550       make\n",
       "1149117        get\n",
       "251097        best\n",
       "2128916      price\n",
       "1019034       find\n",
       "383137         buy\n",
       "1069061       food\n",
       "1933196      order\n",
       "88702       amazon\n",
       "2849770       time\n",
       "2231983     realli\n",
       "854640         eat\n",
       "2637615      store\n",
       "799305         dog\n",
       "3135268      would\n",
       "            ...   \n",
       "3031509       want\n",
       "1030844      first\n",
       "2454181       ship\n",
       "3045051      water\n",
       "1815777       need\n",
       "1099117       free\n",
       "205151         bar\n",
       "3116145     wonder\n",
       "1598803      local\n",
       "618307       cooki\n",
       "849287        easi\n",
       "1475198       keep\n",
       "3051460        way\n",
       "417932        cant\n",
       "1339075        hot\n",
       "1105181      fresh\n",
       "1641490       made\n",
       "922660        ever\n",
       "83555        alway\n",
       "936199       excel\n",
       "274010         bit\n",
       "1615976        lot\n",
       "925109       everi\n",
       "2482747       sinc\n",
       "2821173      think\n",
       "1727410       milk\n",
       "1664342       mani\n",
       "2370453       sauc\n",
       "761033      differ\n",
       "2657844      stuff\n",
       "Name: feature, Length: 100, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top 100 feature for positive class\n",
    "feature_prob.sort_values(by=['positive'],axis=0,ascending=False)['feature'][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1850292           not\n",
       "2736080          tast\n",
       "1563628          like\n",
       "2147763       product\n",
       "2787022           the\n",
       "3135268         would\n",
       "543608          coffe\n",
       "1910210           one\n",
       "1042761        flavor\n",
       "2907733           tri\n",
       "383137            buy\n",
       "1933196         order\n",
       "322642            box\n",
       "2826533          this\n",
       "2752048           tea\n",
       "1149117           get\n",
       "1185785          good\n",
       "807909           dont\n",
       "776139     disappoint\n",
       "2974007           use\n",
       "917016           even\n",
       "190642            bag\n",
       "1069061          food\n",
       "187587            bad\n",
       "88702          amazon\n",
       "2179667       purchas\n",
       "315343         bought\n",
       "1972621        packag\n",
       "1786405          much\n",
       "1608367          look\n",
       "              ...    \n",
       "675431            cup\n",
       "2637615         store\n",
       "2454181          ship\n",
       "1969625          pack\n",
       "1445720           ive\n",
       "74927            also\n",
       "181608           back\n",
       "944856         expect\n",
       "2817112         thing\n",
       "2657844         stuff\n",
       "1588739         littl\n",
       "1903232           old\n",
       "1748609           mix\n",
       "570250        compani\n",
       "761033         differ\n",
       "2625958         still\n",
       "205151            bar\n",
       "603397        contain\n",
       "3067499          well\n",
       "1348038         howev\n",
       "441136            cat\n",
       "3137384     would not\n",
       "1019034          find\n",
       "1333693          hope\n",
       "2704921         sweet\n",
       "618307          cooki\n",
       "2800629         there\n",
       "1851337       not buy\n",
       "797346         doesnt\n",
       "3119564          wont\n",
       "Name: feature, Length: 100, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top 100 feature for negative class\n",
    "feature_prob.sort_values(by=['negative'],axis=0,ascending=False)['feature'][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using avg-w2v and multinomial naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "sentence_list=[] # list for storing list of words\n",
    "for sentence in df_sample['CleanText'].values:\n",
    "    li=sentence.split()\n",
    "    sentence_list.append(li)\n",
    "w2v_model=gensim.models.Word2Vec(sentence_list,min_count=5,size=50) # training our word2vec model and note :list of sentences is list of list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_vec(list_of_sentence):\n",
    "    vec_list=[]\n",
    "    for sentence in list_of_sentence:\n",
    "        vec=np.zeros(50)\n",
    "        count=0\n",
    "        for word in sentence.split():\n",
    "            try:\n",
    "                vec=vec+w2v_model.wv[word]\n",
    "                count+=1\n",
    "            except:\n",
    "                continue\n",
    "        vec=vec/count\n",
    "        vec_list.append(vec)\n",
    "    return vec_list\n",
    "\n",
    "list_of_sentence=[] # list of each review\n",
    "for sentence in df_sample['CleanText'].values:\n",
    "    list_of_sentence.append(sentence)\n",
    "    \n",
    "w2v_data=get_sentence_vec(list_of_sentence) # calculating sentence vector using Word2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=pd.DataFrame(w2v_data)  # converting w2v_data to dataframe for nan \n",
    "dataframe=dataframe.fillna(0)   #filling nan value with 0\n",
    "w2v_data=MinMaxScaler(feature_range=(0, 1)).fit_transform(dataframe) # normalization on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=w2v_data #creating out feature matrix and label vector\n",
    "y=df_sample['class'].apply(lambda string: 1 if string=='positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,shuffle=False) # 70-30 split without shuffling(used for TBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tnr(y_true,y_pred): \n",
    "    tn, fp, fn, tp = confusion_matrix(y_true,y_pred).ravel()\n",
    "    return tn/(tn+fp)\n",
    "\n",
    "def fpr(y_true,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true,y_pred).ravel()\n",
    "    return fp/(tn+fp)\n",
    "\n",
    "def fnr(y_true,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true,y_pred).ravel()\n",
    "    return fn/(fn+tp)\n",
    "\n",
    "def tpr(y_true,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true,y_pred).ravel()\n",
    "    return tp/(fn+tp)\n",
    "\n",
    "tnr=make_scorer(tnr)\n",
    "fpr=make_scorer(fpr)\n",
    "fnr=make_scorer(fnr)\n",
    "tpr=make_scorer(tpr)\n",
    "\n",
    "scoring={'accuracy':'accuracy',\n",
    "    'tnr':tnr,\n",
    "    'fnr':fnr,\n",
    "    'fpr':fpr,\n",
    "    'tpr':tpr,\n",
    "    'precision':'precision',\n",
    "    'recall':'recall',\n",
    "    'f1':'f1',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.metrics import accuracy_score#training stage\n",
    "tscv=TimeSeriesSplit(n_splits=10) # timeseries split for using timeseries based cross-validation\n",
    "weight_vector_y_train=compute_sample_weight(class_weight='balanced',y=y_train) #oversampling to balance the dataset\n",
    "#creating list's to store scores for each value of alpha for each score\n",
    "accuracy=[]\n",
    "tpr=[]\n",
    "tnr=[]\n",
    "fpr=[]\n",
    "fnr=[]\n",
    "f1=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "alpha_list=[0.7,0.8,0.9,1,1.2,1.4] # alpha used for cross validation\n",
    "for alpha in alpha_list:\n",
    "    nb_clf_model=MultinomialNB(alpha=alpha)\n",
    "    cv_dict=cross_validate(nb_clf_model,X_train,y_train,scoring=scoring,cv=tscv.split(X_train),fit_params={'sample_weight':weight_vector_y_train})\n",
    "    accuracy.append(np.mean(cv_dict['test_accuracy']))\n",
    "    tnr.append(np.mean(cv_dict['test_tnr']))\n",
    "    fnr.append(np.mean(cv_dict['test_fnr']))\n",
    "    fpr.append(np.mean(cv_dict['test_fpr']))\n",
    "    tpr.append(np.mean(cv_dict['test_tpr']))\n",
    "    f1.append(np.mean(cv_dict['test_f1']))\n",
    "    precision.append(np.mean(cv_dict['test_precision']))\n",
    "    recall.append(np.mean(cv_dict['test_recall'].mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TNR</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FNR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Precesion</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>0.854202</td>\n",
       "      <td>0.127347</td>\n",
       "      <td>0.985602</td>\n",
       "      <td>0.014398</td>\n",
       "      <td>0.872653</td>\n",
       "      <td>0.862293</td>\n",
       "      <td>0.985602</td>\n",
       "      <td>0.919125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.854202</td>\n",
       "      <td>0.127347</td>\n",
       "      <td>0.985602</td>\n",
       "      <td>0.014398</td>\n",
       "      <td>0.872653</td>\n",
       "      <td>0.862293</td>\n",
       "      <td>0.985602</td>\n",
       "      <td>0.919125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>0.854202</td>\n",
       "      <td>0.127347</td>\n",
       "      <td>0.985602</td>\n",
       "      <td>0.014398</td>\n",
       "      <td>0.872653</td>\n",
       "      <td>0.862293</td>\n",
       "      <td>0.985602</td>\n",
       "      <td>0.919125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.854202</td>\n",
       "      <td>0.127347</td>\n",
       "      <td>0.985602</td>\n",
       "      <td>0.014398</td>\n",
       "      <td>0.872653</td>\n",
       "      <td>0.862293</td>\n",
       "      <td>0.985602</td>\n",
       "      <td>0.919125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2</th>\n",
       "      <td>0.854202</td>\n",
       "      <td>0.127347</td>\n",
       "      <td>0.985602</td>\n",
       "      <td>0.014398</td>\n",
       "      <td>0.872653</td>\n",
       "      <td>0.862293</td>\n",
       "      <td>0.985602</td>\n",
       "      <td>0.919125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.4</th>\n",
       "      <td>0.854197</td>\n",
       "      <td>0.127319</td>\n",
       "      <td>0.985602</td>\n",
       "      <td>0.014398</td>\n",
       "      <td>0.872681</td>\n",
       "      <td>0.862289</td>\n",
       "      <td>0.985602</td>\n",
       "      <td>0.919122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy       TNR       TPR       FNR       FPR  Precesion    Recall  \\\n",
       "alpha                                                                          \n",
       "0.7    0.854202  0.127347  0.985602  0.014398  0.872653   0.862293  0.985602   \n",
       "0.8    0.854202  0.127347  0.985602  0.014398  0.872653   0.862293  0.985602   \n",
       "0.9    0.854202  0.127347  0.985602  0.014398  0.872653   0.862293  0.985602   \n",
       "1.0    0.854202  0.127347  0.985602  0.014398  0.872653   0.862293  0.985602   \n",
       "1.2    0.854202  0.127347  0.985602  0.014398  0.872653   0.862293  0.985602   \n",
       "1.4    0.854197  0.127319  0.985602  0.014398  0.872681   0.862289  0.985602   \n",
       "\n",
       "             F1  \n",
       "alpha            \n",
       "0.7    0.919125  \n",
       "0.8    0.919125  \n",
       "0.9    0.919125  \n",
       "1.0    0.919125  \n",
       "1.2    0.919125  \n",
       "1.4    0.919122  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df=pd.DataFrame(OrderedDict({'Accuracy':accuracy,'TNR':tnr,'TPR':tpr,'FNR':fnr,'FPR':fpr,'Precesion':precision,'Recall':recall,'F1':f1}),index=alpha_list)   \n",
    "score_df.index.name='alpha'\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_score(y_true,y_predicted,sample_weight=None):\n",
    "    '''\n",
    "    calculation of all 4 ratios of confusion matrix\n",
    "    and returing dict consisting all rations\n",
    "    '''\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true,y_predicted).ravel()\n",
    "    tnr=tn/(tn+fp)\n",
    "    fpr=fp/(tn+fp)\n",
    "    fnr=fn/(fn+tp)\n",
    "    tpr=tp/(fn+tp)\n",
    "    return {'tnr':tnr,'tpr':tpr,'fpr':fpr,'fnr':fnr}\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please enter optimal alpha  0.7\n",
      "Accuracy=  79.3156133555  %\n",
      "TNR=  83.4090017376  %\n",
      "TPR=  75.2222249734  %\n",
      "FNR=  24.7777750266  %\n",
      "FPR=  16.5909982624  %\n",
      "Precesion=  81.9296200725  %\n",
      "Recall=  75.2222249734  %\n",
      "F1=  78.4327834176  %\n"
     ]
    }
   ],
   "source": [
    "#test stage/evaluation stage\n",
    "#retrianing our model with optimal hyperparameter:\n",
    "optimal_alpha=float(input('please enter optimal alpha  '))\n",
    "nb_clf_model=MultinomialNB(alpha=optimal_alpha)\n",
    "weight_vector_y_train=compute_sample_weight(class_weight='balanced',y=y_train) #oversampling to balance the dataset\n",
    "nb_clf_model.fit(X_train,y_train,sample_weight=weight_vector_y_train)\n",
    "\n",
    "#evaluating our model\n",
    "weight_vector_y_test=compute_sample_weight(class_weight='balanced',y=y_test) #oversampling to balance the dataset\n",
    "y_predicted=nb_clf_model.predict(X_test)\n",
    "accuracy=accuracy_score(y_test,y_predicted,normalize=True,sample_weight=weight_vector_y_test)\n",
    "precesion=precision_score(y_test,y_predicted,sample_weight=weight_vector_y_test)\n",
    "recall=recall_score(y_test,y_predicted,sample_weight=weight_vector_y_test)\n",
    "f1=f1_score(y_test,y_predicted,sample_weight=weight_vector_y_test)\n",
    "confusion_result=confusion_score(y_test,y_predicted,sample_weight=weight_vector_y_test)\n",
    "print('Accuracy= ',accuracy*100,' %')\n",
    "print('TNR= ',confusion_result['tnr']*100,' %')\n",
    "print('TPR= ',confusion_result['tpr']*100,' %')\n",
    "print('FNR= ',confusion_result['fnr']*100,' %')\n",
    "print('FPR= ',confusion_result['fpr']*100,' %')\n",
    "print('Precesion= ',precesion*100,' %')\n",
    "print('Recall= ',recall*100,' %')\n",
    "print('F1= ',f1*100,' %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using tf-idf weighted-w2v and multinomial naive bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "list_of_sentence=[] #using cleaned text\n",
    "for sentence in df_sample['CleanText'].values:\n",
    "    list_of_sentence.append(sentence)\n",
    "\n",
    "tfidf_model=TfidfVectorizer(ngram_range=(1,2))\n",
    "tfidf_review_matrix=tfidf_model.fit_transform(list_of_sentence) #calculating tf-idf vectors\n",
    "\n",
    "\n",
    "sentence_list=[] # list for storing list of words \n",
    "for sentence in df_sample['CleanText'].values:\n",
    "    li=sentence.split()\n",
    "    sentence_list.append(li)\n",
    "w2v_model=gensim.models.Word2Vec(sentence_list,min_count=5,size=50) #training w2v model and note data should be list of list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_vec_tfidf(list_of_sentence):\n",
    "\n",
    "    feature_name=tfidf_model.get_feature_names()\n",
    "    di={ key:value for value,key in enumerate(tfidf_model.get_feature_names())}  #using dictionary to store feature name and index\n",
    "    #it made our algo to have less time complexity \n",
    "    vec_list=[]\n",
    "    row=0\n",
    "    for sentence in list_of_sentence:\n",
    "        sent_vec=np.zeros(50)\n",
    "        weighted_sum=0\n",
    "        for word in sentence.split():\n",
    "            \n",
    "            try:\n",
    "                tfidf_value=tfidf_review_matrix[row,di[word]]\n",
    "                vec=w2v_model.wv[word]\n",
    "                sent_vec=sent_vec+(vec*tfidf_value)\n",
    "                weighted_sum+=tfidf_value\n",
    "            except:\n",
    "                continue\n",
    "        sent_vec=sent_vec/weighted_sum\n",
    "        vec_list.append(sent_vec)\n",
    "        row+=1\n",
    "    return vec_list\n",
    "tfidfw2v_data=get_sentence_vec_tfidf(list_of_sentence) # calculating sentence vector using Word2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=pd.DataFrame(tfidfw2v_data)  # converting w2v_data to dataframe for nan \n",
    "dataframe=dataframe.fillna(0)   #filling nan value with 0\n",
    "tfidfw2v_data=MinMaxScaler(feature_range=(0, 1)).fit_transform(dataframe) # normalization on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=tfidfw2v_data #creating out feature matrix and label vector\n",
    "y=df_sample['class'].apply(lambda string: 1 if string=='positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,shuffle=False) # 70-30 split without shuffling(used for TBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tnr(y_true,y_pred): \n",
    "    tn, fp, fn, tp = confusion_matrix(y_true,y_pred).ravel()\n",
    "    return tn/(tn+fp)\n",
    "\n",
    "def fpr(y_true,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true,y_pred).ravel()\n",
    "    return fp/(tn+fp)\n",
    "\n",
    "def fnr(y_true,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true,y_pred).ravel()\n",
    "    return fn/(fn+tp)\n",
    "\n",
    "def tpr(y_true,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true,y_pred).ravel()\n",
    "    return tp/(fn+tp)\n",
    "\n",
    "tnr=make_scorer(tnr)\n",
    "fpr=make_scorer(fpr)\n",
    "fnr=make_scorer(fnr)\n",
    "tpr=make_scorer(tpr)\n",
    "\n",
    "scoring={'accuracy':'accuracy',\n",
    "    'tnr':tnr,\n",
    "    'fnr':fnr,\n",
    "    'fpr':fpr,\n",
    "    'tpr':tpr,\n",
    "    'precision':'precision',\n",
    "    'recall':'recall',\n",
    "    'f1':'f1',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.metrics import accuracy_score#training stage\n",
    "tscv=TimeSeriesSplit(n_splits=10) # timeseries split for using timeseries based cross-validation\n",
    "weight_vector_y_train=compute_sample_weight(class_weight='balanced',y=y_train) #oversampling to balance the dataset\n",
    "#creating list's to store scores for each value of alpha for each score\n",
    "accuracy=[]\n",
    "tpr=[]\n",
    "tnr=[]\n",
    "fpr=[]\n",
    "fnr=[]\n",
    "f1=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "alpha_list=[0.7,0.8,0.9,1,1.2,1.4] # alpha used for cross validation\n",
    "for alpha in alpha_list:\n",
    "    nb_clf_model=MultinomialNB(alpha=alpha)\n",
    "    cv_dict=cross_validate(nb_clf_model,X_train,y_train,scoring=scoring,cv=tscv.split(X_train),fit_params={'sample_weight':weight_vector_y_train})\n",
    "    accuracy.append(np.mean(cv_dict['test_accuracy']))\n",
    "    tnr.append(np.mean(cv_dict['test_tnr']))\n",
    "    fnr.append(np.mean(cv_dict['test_fnr']))\n",
    "    fpr.append(np.mean(cv_dict['test_fpr']))\n",
    "    tpr.append(np.mean(cv_dict['test_tpr']))\n",
    "    f1.append(np.mean(cv_dict['test_f1']))\n",
    "    precision.append(np.mean(cv_dict['test_precision']))\n",
    "    recall.append(np.mean(cv_dict['test_recall'].mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TNR</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FNR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Precesion</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>0.750464</td>\n",
       "      <td>0.783054</td>\n",
       "      <td>0.744559</td>\n",
       "      <td>0.255441</td>\n",
       "      <td>0.216946</td>\n",
       "      <td>0.948853</td>\n",
       "      <td>0.744559</td>\n",
       "      <td>0.82913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.750464</td>\n",
       "      <td>0.783054</td>\n",
       "      <td>0.744559</td>\n",
       "      <td>0.255441</td>\n",
       "      <td>0.216946</td>\n",
       "      <td>0.948853</td>\n",
       "      <td>0.744559</td>\n",
       "      <td>0.82913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>0.750464</td>\n",
       "      <td>0.783054</td>\n",
       "      <td>0.744559</td>\n",
       "      <td>0.255441</td>\n",
       "      <td>0.216946</td>\n",
       "      <td>0.948853</td>\n",
       "      <td>0.744559</td>\n",
       "      <td>0.82913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.750464</td>\n",
       "      <td>0.783054</td>\n",
       "      <td>0.744559</td>\n",
       "      <td>0.255441</td>\n",
       "      <td>0.216946</td>\n",
       "      <td>0.948853</td>\n",
       "      <td>0.744559</td>\n",
       "      <td>0.82913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2</th>\n",
       "      <td>0.750464</td>\n",
       "      <td>0.783054</td>\n",
       "      <td>0.744559</td>\n",
       "      <td>0.255441</td>\n",
       "      <td>0.216946</td>\n",
       "      <td>0.948853</td>\n",
       "      <td>0.744559</td>\n",
       "      <td>0.82913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.4</th>\n",
       "      <td>0.750464</td>\n",
       "      <td>0.783054</td>\n",
       "      <td>0.744559</td>\n",
       "      <td>0.255441</td>\n",
       "      <td>0.216946</td>\n",
       "      <td>0.948853</td>\n",
       "      <td>0.744559</td>\n",
       "      <td>0.82913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy       TNR       TPR       FNR       FPR  Precesion    Recall  \\\n",
       "alpha                                                                          \n",
       "0.7    0.750464  0.783054  0.744559  0.255441  0.216946   0.948853  0.744559   \n",
       "0.8    0.750464  0.783054  0.744559  0.255441  0.216946   0.948853  0.744559   \n",
       "0.9    0.750464  0.783054  0.744559  0.255441  0.216946   0.948853  0.744559   \n",
       "1.0    0.750464  0.783054  0.744559  0.255441  0.216946   0.948853  0.744559   \n",
       "1.2    0.750464  0.783054  0.744559  0.255441  0.216946   0.948853  0.744559   \n",
       "1.4    0.750464  0.783054  0.744559  0.255441  0.216946   0.948853  0.744559   \n",
       "\n",
       "            F1  \n",
       "alpha           \n",
       "0.7    0.82913  \n",
       "0.8    0.82913  \n",
       "0.9    0.82913  \n",
       "1.0    0.82913  \n",
       "1.2    0.82913  \n",
       "1.4    0.82913  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df=pd.DataFrame(OrderedDict({'Accuracy':accuracy,'TNR':tnr,'TPR':tpr,'FNR':fnr,'FPR':fpr,'Precesion':precision,'Recall':recall,'F1':f1}),index=alpha_list)   \n",
    "score_df.index.name='alpha'\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_score(y_true,y_predicted,sample_weight=None):\n",
    "    '''\n",
    "    calculation of all 4 ratios of confusion matrix\n",
    "    and returing dict consisting all rations\n",
    "    '''\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true,y_predicted).ravel()\n",
    "    tnr=tn/(tn+fp)\n",
    "    fpr=fp/(tn+fp)\n",
    "    fnr=fn/(fn+tp)\n",
    "    tpr=tp/(fn+tp)\n",
    "    return {'tnr':tnr,'tpr':tpr,'fpr':fpr,'fnr':fnr}\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please enter optimal alpha  0.7\n",
      "Accuracy=  77.4580440742  %\n",
      "TNR=  77.4614021767  %\n",
      "TPR=  77.4546859717  %\n",
      "FNR=  22.5453140283  %\n",
      "FPR=  22.5385978233  %\n",
      "Precesion=  77.4598883365  %\n",
      "Recall=  77.4546859716  %\n",
      "F1=  77.4572870667  %\n"
     ]
    }
   ],
   "source": [
    "#test stage/evaluation stage\n",
    "#retrianing our model with optimal hyperparameter:\n",
    "optimal_alpha=float(input('please enter optimal alpha  '))\n",
    "nb_clf_model=MultinomialNB(alpha=optimal_alpha)\n",
    "weight_vector_y_train=compute_sample_weight(class_weight='balanced',y=y_train) #oversampling to balance the dataset\n",
    "nb_clf_model.fit(X_train,y_train,sample_weight=weight_vector_y_train)\n",
    "\n",
    "#evaluating our model\n",
    "weight_vector_y_test=compute_sample_weight(class_weight='balanced',y=y_test) #oversampling to balance the dataset\n",
    "y_predicted=nb_clf_model.predict(X_test)\n",
    "accuracy=accuracy_score(y_test,y_predicted,normalize=True,sample_weight=weight_vector_y_test)\n",
    "precesion=precision_score(y_test,y_predicted,sample_weight=weight_vector_y_test)\n",
    "recall=recall_score(y_test,y_predicted,sample_weight=weight_vector_y_test)\n",
    "f1=f1_score(y_test,y_predicted,sample_weight=weight_vector_y_test)\n",
    "confusion_result=confusion_score(y_test,y_predicted,sample_weight=weight_vector_y_test)\n",
    "print('Accuracy= ',accuracy*100,' %')\n",
    "print('TNR= ',confusion_result['tnr']*100,' %')\n",
    "print('TPR= ',confusion_result['tpr']*100,' %')\n",
    "print('FNR= ',confusion_result['fnr']*100,' %')\n",
    "print('FPR= ',confusion_result['fpr']*100,' %')\n",
    "print('Precesion= ',precesion*100,' %')\n",
    "print('Recall= ',recall*100,' %')\n",
    "print('F1= ',f1*100,' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
